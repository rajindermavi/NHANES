{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wrangling NHANES Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "### Quantify Missing Data\n",
    "\n",
    "In this notebook we take a look at the quality of the data, namely the quantity of missing data. We drop rows and columns missing excessive numbers of values. We also consider special columns we use toward feature engineering.\n",
    "\n",
    "### Split train, validation, test data\n",
    "\n",
    "After the dataset is ridden of rows and columns missing excessive values, we split the remaining dataset into train, validation, and test data. \n",
    "\n",
    "### Impute Missing Data\n",
    "\n",
    "We will see that some data is missing, desicions about data imputation are made using the training data set and applied to the validation and test sets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import GroupImputer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_pickle(\"preprocessed_data.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n,m = df.shape\n",
    "\n",
    "print(f'The dataframe consists of {n} rows and {m} columns.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View missing data by column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def col_frac_missing(df, threshold = 0.05):\n",
    "    fraction_null = df.isnull().sum()/len(df)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.xticks(np.arange(len(fraction_null)),fraction_null.index,rotation='vertical')\n",
    "    plt.ylabel('fraction of rows with missing data')\n",
    "    plt.bar(np.arange(len(fraction_null)),fraction_null)\n",
    "    plt.axhline(2*threshold,linewidth=2, color='r')\n",
    "    plt.axhline(threshold,linewidth=2, color='g')\n",
    "    plt.title('Proportion of missing values by column.')\n",
    "    plt.show()\n",
    "    return fraction_null"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "column_fraction_null = col_frac_missing(df,threshold = 0.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see quite a few columns have missing data over the 5% and 10% threshold. There is a stand out column DiabAge -- the age a person is diagnosed with diabetes -- but of course if someone is never diagnosed this value is missing by design. Therefore we must come back to this column later. Next we will attempt to drop rows missing the most values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View missing data by row"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frac_index_null = df.isnull().sum(1).sort_values(ascending = False)\n",
    "\n",
    "frac_index_null.reset_index()[0].plot()\n",
    "plt.title('Frequency of missing values by row.')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There seem to be roughly 5000 SPs missing well over 5 values. We will investigate whether dropping such rows improves the missing data by columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop SPs missing 5 or more values\n",
    "df_depleted = df[df.isnull().sum(1)<5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "column_fraction_null = col_frac_missing(df_depleted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see LBXGLU, LDL, Triglicerides miss very large number of values. These columns are not part of our predictive analysis, but will be used in exploratory analysis, so we will leave it in for now. FastFood and and PregnantNow are still missing a large numbe of values, so we will drop them from the original dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop columns with many missing values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop columns from original dataframe missing many values\n",
    "df.drop(['PregnantNow','FastFood'],axis=1,inplace=True)\n",
    "# Drop SPs missing 5 or more values\n",
    "df_depleted = df[df.isnull().sum(1)<5].copy()\n",
    "column_fraction_null = col_frac_missing(df_depleted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The columns Alcohol and CholHist still seem to be missing a high number of values. Let us view the portion missing for these columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Portion missing:')\n",
    "column_fraction_null.loc[['Alcohol','CholHist']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alcohol is missing a high number of values at 8.2%, unfortunately there is not a similar feature so it would be a better not to remove it. CholHist (Whether a doctor has told you you have high cholesterol) likely correlates well with HyperHist (Whether a doctor has told you you have hypertension). Let us view the correlation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr = (df_depleted[['HyperHist','CholHist']].corr()).iloc[0,1]\n",
    "\n",
    "print(f'The correlation coefficient for Hypertensive History with Cholestorol History is {corr:.3}.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although the correlation appears high, the missing values are only borderline, so we will keep the feature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing the DiabAge variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = df['DiabHist'].value_counts()\n",
    "print(f'SPs not told they have diabetes: {x[0.0]}')\n",
    "print(f'SPs told they have diabetes: {x[1.0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The majority of SPs have not been diagnosed with diabetes, which explains the large number of missing values in DiabAge. We will construct a new feature DiabHistAge which combines these two variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_depleted['DiabHistAge'] = 0\n",
    "df_depleted.loc[(df_depleted['DiabAge'] > 50),'DiabHistAge'] = 1\n",
    "df_depleted.loc[(df_depleted['DiabAge'] > 50),'DiabHistAge'] = 2\n",
    "df_depleted.drop(['DiabHist','DiabAge'],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again let us view missing values by column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "column_fraction_null = col_frac_missing(df_depleted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n,m=df_depleted.shape\n",
    "\n",
    "print(f'The dataframe consists of {n} rows and {m} columns.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_depleted, test_size = 0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imputations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Missing proportions in demographic columns')\n",
    "column_fraction_null[['Age','Gender','Ethnicity']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No values are missing from these demographics columns, so we will attempt to impute by these groups. First we verify which columns are missing sufficiently few values per group. We convert Age to AgeGroup for imputation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train = df_train.join((df_train['Age'].apply(lambda x: np.floor(x/20))).rename('AgeGroup')) \n",
    "df_test = df_test.join((df_test['Age'].apply(lambda x: np.floor(x/20))).rename('AgeGroup'))\n",
    "\n",
    "demo = ['Gender','AgeGroup','Ethnicity']\n",
    "\n",
    "# Find proportion missing per demographic\n",
    "min_prop = (df_train.groupby(by = demo).count().apply(lambda x: x/max(x),axis = 1)).min()\n",
    "max_prop = (df_train.groupby(by = demo).count().apply(lambda x: x/max(x),axis = 1)).max()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Columns requiring imputation missing 5% data or less in all demo groups.')\n",
    "min_prop[(min_prop >= 0.95) & (min_prop < 1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Columns missing over 5% data in at least one demo group.')\n",
    "min_prop[min_prop < 0.95]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Impute by demographic for those demos missing 5% or under per group\n",
    "demo_impute = min_prop[(min_prop >= 0.95) & (min_prop < 1)].index\n",
    "\n",
    "for col in demo_impute:\n",
    "    DemoImputer = GroupImputer(demo, col, metric = 'mode')\n",
    "    DemoImputer.fit(df_train)\n",
    "    df_train = pd.DataFrame(DemoImputer.transform(df_train),columns = df_train.columns)\n",
    "    df_test = pd.DataFrame(DemoImputer.transform(df_test),columns = df_test.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the data types.\n",
    "\n",
    "Most variables in the dataset are categorical. We ensure that such variables are set as integers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_depleted.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Subset of continuous variables:\n",
    "float_vars = {'WTINT2YR',\n",
    "                'HoursSlept',\n",
    "                'MaxWeight',\n",
    "                'LegLen',\n",
    "                'ArmCirc',\n",
    "                'ArmLen',\n",
    "                'Weight',\n",
    "                'Systolic',\n",
    "                'Diastolic'\n",
    "            }\n",
    "\n",
    "int_vars = (df_depleted.columns).difference(float_vars)\n",
    "\n",
    "int_vars = {var:'int8' for var in int_vars}\n",
    "\n",
    "df_depleted.astype(int_vars)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finally we save the data\n",
    "\n",
    "Most of the columns have low numbers of missing values, aside from the laboratory data, which we keep only to study in the EDA, not for the purpose of predictive analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_depleted.to_pickle(\"wrangled_data.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}