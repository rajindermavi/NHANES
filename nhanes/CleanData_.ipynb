{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Wrangling for NHANES Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we will clean data which was collected from the NHANES website: www.cdc.gov/nchs/nhanes/index.htm. This is the first step towards creating a predictive model for hypertension and diabetes. Aside from typical cleaning tasks carried out in data wrangling, there are special considerations due to the nature of the survey."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filling in cells skipped by design in the survey\n",
    "\n",
    "The NHANES survey methods indicate occasionally skipping questions based on previous answers. For example, if the answer to the question 'Have you smoked 100 cigarettes in your lifetime?' is no, then the following question 'Are you currently smoking?' is skipped. In such columns we expect large numbers of missing values and they are easily filled in."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treating refused / don't know as missing\n",
    "\n",
    "The NHANES survey taker records responses of the SP 'refused(to answer)' and 'don't know'. Such answers are coded as numbers which are documented on the NHANES website. There are not enough of these values overall to treat them as a separate category, so we will treat them as we treat the other missing values in the data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_pickle(\"raw_data.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Before we begin cleaning we drop SPs below age 20 \n",
    "df = df[df.RIDAGEYR >= 20]\n",
    "# Change floating points near zero to zero:\n",
    "df = df.round()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print('The size of the dataset: {0} rows, {1} columns '.format(*df.shape))\n",
    "# Let us view the data\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The size of the dataset: 34770 rows, 62 columns \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         RIDRETH1  RIDAGEYR  DMDHREDU  RIAGENDR  INDHHIN2  ALQ150  BPQ020  \\\n",
       "SEQN                                                                        \n",
       "41475.0       5.0      62.0       4.0       2.0       6.0     2.0     1.0   \n",
       "41477.0       3.0      71.0       3.0       1.0       5.0     2.0     1.0   \n",
       "41479.0       1.0      52.0       1.0       1.0       8.0     2.0     2.0   \n",
       "41481.0       4.0      21.0       4.0       1.0       6.0     2.0     2.0   \n",
       "41482.0       1.0      64.0       4.0       1.0      15.0     1.0     1.0   \n",
       "\n",
       "         BPQ080  CDQ001  CDQ010  ...  LBXTR  LBDLDL  LBXTC  PHAFSTHR  PHDSESN  \\\n",
       "SEQN                             ...                                            \n",
       "41475.0     2.0     1.0     1.0  ...    NaN     NaN  179.0       7.0      1.0   \n",
       "41477.0     1.0     2.0     2.0  ...    NaN     NaN  191.0       2.0      1.0   \n",
       "41479.0     NaN     2.0     2.0  ...   99.0   121.0  188.0      14.0      0.0   \n",
       "41481.0     NaN     NaN     NaN  ...    NaN     NaN    NaN      12.0      0.0   \n",
       "41482.0     2.0     2.0     1.0  ...    NaN     NaN  158.0       1.0      1.0   \n",
       "\n",
       "         LBXGLU  OHQ845  ALQ151  SLD012  DMDHREDZ  \n",
       "SEQN                                               \n",
       "41475.0     NaN     NaN     NaN     NaN       NaN  \n",
       "41477.0     NaN     NaN     NaN     NaN       NaN  \n",
       "41479.0   113.0     NaN     NaN     NaN       NaN  \n",
       "41481.0     NaN     NaN     NaN     NaN       NaN  \n",
       "41482.0     NaN     NaN     NaN     NaN       NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>DMDHREDU</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>INDHHIN2</th>\n",
       "      <th>ALQ150</th>\n",
       "      <th>BPQ020</th>\n",
       "      <th>BPQ080</th>\n",
       "      <th>CDQ001</th>\n",
       "      <th>CDQ010</th>\n",
       "      <th>...</th>\n",
       "      <th>LBXTR</th>\n",
       "      <th>LBDLDL</th>\n",
       "      <th>LBXTC</th>\n",
       "      <th>PHAFSTHR</th>\n",
       "      <th>PHDSESN</th>\n",
       "      <th>LBXGLU</th>\n",
       "      <th>OHQ845</th>\n",
       "      <th>ALQ151</th>\n",
       "      <th>SLD012</th>\n",
       "      <th>DMDHREDZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEQN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41475.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41477.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41479.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41481.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41482.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Let us view the details about each column\n",
    "print('Details about each column.\\n')\n",
    "df.info()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Details about each column.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 34770 entries, 41475.0 to 102956.0\n",
      "Data columns (total 62 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   RIDRETH1  34770 non-null  float64\n",
      " 1   RIDAGEYR  34770 non-null  float64\n",
      " 2   DMDHREDU  28300 non-null  float64\n",
      " 3   RIAGENDR  34770 non-null  float64\n",
      " 4   INDHHIN2  33998 non-null  float64\n",
      " 5   ALQ150    9086 non-null   float64\n",
      " 6   BPQ020    34770 non-null  float64\n",
      " 7   BPQ080    31192 non-null  float64\n",
      " 8   CDQ001    23220 non-null  float64\n",
      " 9   CDQ010    23219 non-null  float64\n",
      " 10  DID040    4624 non-null   float64\n",
      " 11  DIQ010    34770 non-null  float64\n",
      " 12  DBD910    34735 non-null  float64\n",
      " 13  DBD900    26393 non-null  float64\n",
      " 14  DBD905    34734 non-null  float64\n",
      " 15  DBD895    34770 non-null  float64\n",
      " 16  DBQ197    34770 non-null  float64\n",
      " 17  KIQ026    34769 non-null  float64\n",
      " 18  KIQ022    34769 non-null  float64\n",
      " 19  KIQ005    30156 non-null  float64\n",
      " 20  DPQ090    29993 non-null  float64\n",
      " 21  DPQ020    30011 non-null  float64\n",
      " 22  DPQ060    30001 non-null  float64\n",
      " 23  OCD150    34763 non-null  float64\n",
      " 24  OCQ180    18367 non-null  float64\n",
      " 25  OHQ011    5935 non-null   float64\n",
      " 26  PUQ100    30448 non-null  float64\n",
      " 27  PAQ665    34770 non-null  float64\n",
      " 28  PAQ635    34770 non-null  float64\n",
      " 29  PAQ650    34770 non-null  float64\n",
      " 30  PAQ620    34770 non-null  float64\n",
      " 31  PAQ605    34770 non-null  float64\n",
      " 32  RHQ131    15282 non-null  float64\n",
      " 33  RHD143    4330 non-null   float64\n",
      " 34  SLD010H   23466 non-null  float64\n",
      " 35  SMQ020    34769 non-null  float64\n",
      " 36  SMQ040    15289 non-null  float64\n",
      " 37  WHD140    34657 non-null  float64\n",
      " 38  BPXDI1    30635 non-null  float64\n",
      " 39  BPXSY2    31224 non-null  float64\n",
      " 40  BPXSY1    30635 non-null  float64\n",
      " 41  BPXDI2    31224 non-null  float64\n",
      " 42  BPXDI3    31159 non-null  float64\n",
      " 43  BPXSY3    31159 non-null  float64\n",
      " 44  BPXPLS    32056 non-null  float64\n",
      " 45  BMXWT     32997 non-null  float64\n",
      " 46  BMXARMC   31747 non-null  float64\n",
      " 47  BMXBMI    32939 non-null  float64\n",
      " 48  BMXLEG    31329 non-null  float64\n",
      " 49  BMXARML   31751 non-null  float64\n",
      " 50  BMXWAIST  31385 non-null  float64\n",
      " 51  LBDHDD    31377 non-null  float64\n",
      " 52  LBXTR     14877 non-null  float64\n",
      " 53  LBDLDL    14630 non-null  float64\n",
      " 54  LBXTC     31377 non-null  float64\n",
      " 55  PHAFSTHR  32827 non-null  float64\n",
      " 56  PHDSESN   33412 non-null  float64\n",
      " 57  LBXGLU    15341 non-null  float64\n",
      " 58  OHQ845    27451 non-null  float64\n",
      " 59  ALQ151    16771 non-null  float64\n",
      " 60  SLD012    11209 non-null  float64\n",
      " 61  DMDHREDZ  5306 non-null   float64\n",
      "dtypes: float64(62)\n",
      "memory usage: 16.7 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining similar columns\n",
    "\n",
    "The column pairs (DMDHREDU,DMDHREDZ), (ALQ150,ALQ151), and (OHQ011,OHQ845) are essentially similar questions whose wording / categorization was slightly modified over the survey cycles. We first combine these columns.\n",
    "\n",
    "  * When the variable ALQ150 was replaced with ALQ151 the wording was changed from 'Was there ever a period of your life when you drank 5 alcoholic drinks per day?' to 'Was there ever a period of your life when you drank 4/5 alcoholic drinks per day?' (4 for Women, 5 for Men).\n",
    "  * When the variable OHQ011 was replaced with OHQ845 the wording was changed from 'How would you describe the condition of your teeth?' to 'Overall, how would you rate the health of your teeth and gums?'\n",
    "  * When the variable SLD012H was replaced with SLQ012 the method was changed from directly asking 'How many hours do you sleep per night?' to asking for the sleep and wake times and taking the difference.\n",
    "  * When the variable DMDHREDU was replaced with DMDHREDZ the categories for achieving levels less than HS degree and achieving an AA degree were dropped."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Combine ALQ150 and ALQ151\n",
    "df.loc[df['ALQ150'].isna(), 'ALQ150'] = df['ALQ151']\n",
    "df = df.drop(['ALQ151'],axis = 1)\n",
    "\n",
    "# Combine DMDHREDU and DMDHREDZ\n",
    "# DMDHREDU must be recoded before combination:\n",
    "df.loc[(df['DMDHREDU'] == 2),'DMDHREDU'] = 1\n",
    "df.loc[(df['DMDHREDU'] == 3) | (df['DMDHREDU'] == 4),'DMDHREDU'] = 2\n",
    "df.loc[(df['DMDHREDU'] == 5),'DMDHREDU'] = 3\n",
    "# Combination:\n",
    "df.loc[df['DMDHREDU'].isna(), 'DMDHREDU'] = df['DMDHREDZ']\n",
    "df = df.drop(['DMDHREDZ'],axis = 1)\n",
    "\n",
    "# Combine SLD012H and SLQ012\n",
    "df.loc[df['SLD010H'].isna(), 'SLD010H'] = df['SLD012']\n",
    "df = df.drop(['SLD012'],axis = 1)\n",
    "\n",
    "# Combine OHQ011 and OHQ845\n",
    "# OHQ011 must be recoded before combination\n",
    "df['OHQ011'] = df['OHQ011'] - 10\n",
    "# Combination:\n",
    "df.loc[df['OHQ011'].isna(), 'OHQ011'] = df['OHQ845']\n",
    "df = df.drop(['OHQ845'],axis = 1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fixing dependent columns\n",
    "\n",
    "Again, we note some columns are missing a significant number of values. Most of these are due to the survey methodology of skipping certain questions based on previous answers, we will fill in these values first. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Simplify diabetes age column\n",
    "# replace < 1 yr w 1 and (refused / don't know) --> missing\n",
    "df.loc[(df['DID040'] == 666),'DID040'] = 1  \n",
    "df.loc[(df['DID040'] == 777) | (df['DID040'] == 999) ,'DID040'] = np.nan\n",
    "#print('The median value SPs were notified they had diabetes was', df['DID040'].median())\n",
    "\n",
    "#ax = df.plot.hist(y='DID040' )\n",
    "#ax.set_title('Age SPs were told they had diabetes.')\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note not all SPs will have a value in this column. Data will be imputed in the model building phase."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# First we will simplify the diabetes column\n",
    "# DIQ010 (refused / don't know/ missing) --> No\n",
    "df.loc[(df['DIQ010'] == 7) | (df['DIQ010'] == 9),'DIQ010'] = np.nan\n",
    "\n",
    "# For those not told they have diabetes, code 0\n",
    "df.loc[(df['DIQ010'] == 2),'DIQ010'] = 0  \n",
    "# For those told they have diabetes, or borderline diabetes code 1 \n",
    "df.loc[(df['DIQ010'] == 1) | (df['DIQ010'] == 3),'DIQ010'] = 1   \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The column 'DBD895' gives the number of meals SP had out, the column 'DBD900' are the number of fast food meals out. If the 'DBD895' is zero, we set the 'DBD900' value to zero.\n",
    "\n",
    "The column 'OCD150' records whether the SP worked last week, the column 'OCQ180' records the number of hours, if SP did not work last week, the number of hours is zero. \n",
    "\n",
    "The column 'SMQ020' records whether the SP has smoked 100 cigarettes in their life, the column 'SMQ040' records whether the SP is currently a smoker. If the SP has not smoked 100 cigarettes, we categorize them as non smokers.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "# For the Fast food we will fill in 0 if no meals were eaten out\n",
    "df.loc[(df['DBD895'] == 0 ),'DBD900'] = 0    \n",
    "\n",
    "# If SP was not working last week, fill in zero hours worked\n",
    "df.loc[df['OCD150'].isin([2,3,4]),'OCQ180'] = 0    \n",
    "df = df.drop(['OCD150'],axis = 1)\n",
    "\n",
    "# If SP has not smoked 100 cigarettes, then not currently smoking\n",
    "df.loc[(df['SMQ020'] > 1),'SMQ040'] = 3    \n",
    " \n",
    "\n",
    "# Now let us view missing values again\n",
    "print('Number of missing values per column after filling in skipped questions and dropping rows missing blood pressure.')\n",
    "df.isna().sum(axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of missing values per column after filling in skipped questions and dropping rows missing blood pressure.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RIDRETH1        0\n",
       "RIDAGEYR        0\n",
       "DMDHREDU     1164\n",
       "RIAGENDR        0\n",
       "INDHHIN2      772\n",
       "ALQ150       8913\n",
       "BPQ020          0\n",
       "BPQ080       3578\n",
       "CDQ001      11550\n",
       "CDQ010      11551\n",
       "DID040      30193\n",
       "DIQ010         25\n",
       "DBD910         35\n",
       "DBD900         28\n",
       "DBD905         36\n",
       "DBD895          0\n",
       "DBQ197          0\n",
       "KIQ026          1\n",
       "KIQ022          1\n",
       "KIQ005       4614\n",
       "DPQ090       4777\n",
       "DPQ020       4759\n",
       "DPQ060       4769\n",
       "OCQ180         21\n",
       "OHQ011       1384\n",
       "PUQ100       4322\n",
       "PAQ665          0\n",
       "PAQ635          0\n",
       "PAQ650          0\n",
       "PAQ620          0\n",
       "PAQ605          0\n",
       "RHQ131      19488\n",
       "RHD143      30440\n",
       "SLD010H        95\n",
       "SMQ020          1\n",
       "SMQ040          1\n",
       "WHD140        113\n",
       "BPXDI1       4135\n",
       "BPXSY2       3546\n",
       "BPXSY1       4135\n",
       "BPXDI2       3546\n",
       "BPXDI3       3611\n",
       "BPXSY3       3611\n",
       "BPXPLS       2714\n",
       "BMXWT        1773\n",
       "BMXARMC      3023\n",
       "BMXBMI       1831\n",
       "BMXLEG       3441\n",
       "BMXARML      3019\n",
       "BMXWAIST     3385\n",
       "LBDHDD       3393\n",
       "LBXTR       19893\n",
       "LBDLDL      20140\n",
       "LBXTC        3393\n",
       "PHAFSTHR     1943\n",
       "PHDSESN      1358\n",
       "LBXGLU      19429\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note there are still a large number of missing values for LBXGLU, this is blood sugar which will be used to define our target variable of being diabetic, we will drop the rows containing missing values only when we specialize to the predictive diabetes model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Viewing the number of missing values per row we find the majority have 2 or fewer\n",
    "print('View the number of rows missing k values:')\n",
    "df.isna().sum(axis=1).value_counts().sort_index()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "View the number of rows missing k values:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       18\n",
       "1      665\n",
       "2     3061\n",
       "3     4433\n",
       "4     2544\n",
       "5     5307\n",
       "6     5673\n",
       "7     2603\n",
       "8     2721\n",
       "9     1599\n",
       "10     952\n",
       "11     665\n",
       "12     630\n",
       "13     384\n",
       "14     455\n",
       "15     284\n",
       "16     274\n",
       "17     130\n",
       "18     222\n",
       "19     157\n",
       "20     117\n",
       "21     112\n",
       "22      93\n",
       "23      84\n",
       "24      57\n",
       "25      68\n",
       "26      39\n",
       "27      28\n",
       "28     145\n",
       "29     607\n",
       "30     160\n",
       "31     330\n",
       "32     110\n",
       "33      39\n",
       "34       3\n",
       "35       1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recoding / Cleaning\n",
    "\n",
    "We now run through each survey cleaning and recoding the columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Demographics\n",
    "\n",
    "The demographics survey includes the following features\n",
    "  * Age\n",
    "  * Gender\n",
    "  * Ethnicity\n",
    "  * Education\n",
    "  * Household Income\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Age is a variable taking on integer values.\n",
    "\n",
    "Gender\n",
    "  \n",
    "  * 1 -- Male\n",
    "  * 2 -- Female\n",
    "  \n",
    "Ethnicity\n",
    "\n",
    "  * 1 -- Mexican American\n",
    "  * 2 -- Other Hispanic\n",
    "  * 3 -- Non-Hispanic White\n",
    "  * 4 -- Non-Hispanic Black\n",
    "  * 5 -- Other Race, including Multi-Racial\n",
    "  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# We will clean each survey one at a time, beginning with the Demographics survey.\n",
    "\n",
    "# Demographics\n",
    "# RIDAGEYR age  \n",
    "# RIAGENDR gender OK\n",
    "# RIDRETH1 ethnicity OK\n",
    " \n",
    "\n",
    "df = df.rename(columns={'RIAGENDR':'Gender','RIDAGEYR':'Age','RIDRETH1':'Ethnicity'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Education and Income\n",
    "\n",
    "Note above there are missing values in the education DMDREDU and Income INDHHIN2 columns. We will fill in the missing education values with the mode. The missing income values will be filled with the mean income of the their eduacation level.\n",
    "\n",
    "Household income:\n",
    "\n",
    "  * 1 -- 0 to under 20K\n",
    "  * 2 -- 20K to under 45K\n",
    "  * 3 -- 45K to under 75K\n",
    "  * 4 -- 75K and above\n",
    "  \n",
    "Education:\n",
    "\n",
    "  * 1 -- Less than Highschool\n",
    "  * 2 -- GED / Highschool graduate\n",
    "  * 3 -- College graduate or higher\n",
    "  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Education\n",
    "\n",
    "# Fill in Don't know/ Refused/ Missing --> Mode \n",
    "df.loc[ (df['DMDHREDU'] == 7) | (df['DMDHREDU'] == 9), 'DMDHREDU'] = np.nan\n",
    "df.loc[df['DMDHREDU'].isna(), 'DMDHREDU'] = df['DMDHREDU'].mode()[0]\n",
    "\n",
    "# Household Income \n",
    "# Under 20K\n",
    "df.loc[  df['INDHHIN2'].isin([1,2,3,4,12]), 'INDHHIN2'] = 1\n",
    "# 20K to 45K\n",
    "df.loc[  df['INDHHIN2'].isin([5,6,7]), 'INDHHIN2'] = 2\n",
    "# 45K to 75K\n",
    "df.loc[  df['INDHHIN2'].isin([8,9,10]), 'INDHHIN2'] = 3\n",
    "# Over 75K\n",
    "df.loc[  df['INDHHIN2'].isin([14,15]), 'INDHHIN2'] = 4\n",
    "# Fill in Don't know/ Refused/ Over 20K -->  Missing \n",
    "df.loc[  df['INDHHIN2'].isin([13,77,99]), 'INDHHIN2'] = np.nan\n",
    "\n",
    "# Impute most common income per education level:\n",
    "#edu_inc = df.groupby(by=[\"DMDHREDU\"])[\"INDHHIN2\"].agg(pd.Series.mode).to_dict()\n",
    "#def edu_inc_impute(a,b):\n",
    "#    if np.isnan(b):\n",
    "#        return edu_inc[a]\n",
    "#    else:\n",
    "#        return b\n",
    "#df.loc[df['INDHHIN2'].isna(),'INDHHIN2'] = df.apply(lambda x: edu_inc_impute(x.DMDHREDU,x.INDHHIN2) ,axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "\n",
    "df = df.rename(columns={'INDHHIN2':'HHIncome','DMDHREDU':'Education'})\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alcohol\n",
    "\n",
    "Ever have 4/5 or more drinks every day?\n",
    " \n",
    "Code as \n",
    "  * 0 -- No\n",
    "  * 1 -- Yes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#Alcohol\n",
    "df.loc[ (df['ALQ150'] == 7) | (df['ALQ150'] == 9), 'ALQ150'] = np.nan\n",
    "#df.loc[df['ALQ150'].isna(), 'ALQ150'] = 2\n",
    "df.loc[df['ALQ150'] == 2, 'ALQ150'] = 0\n",
    "df = df.rename(columns={'ALQ150':'Alcohol'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hypertension / Cholesterol\n",
    "\n",
    "Have you been told by your doctor you have hypertension / high cholesterol?\n",
    "\n",
    " \n",
    "Code as \n",
    "  * 0 -- No\n",
    "  * 1 -- Yes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Blood Pressure & Cholesterol\n",
    "\n",
    "# Told you have Hypertension -- refused / don't know -- > missing  \n",
    "df.loc[ (df['BPQ020'] == 7) | (df['BPQ020'] == 9), 'BPQ020'] = np.nan\n",
    "#df.loc[df['BPQ020'].isna(), 'BPQ020'] = 2\n",
    "df.loc[df['BPQ020'] == 2, 'BPQ020'] = 0\n",
    "\n",
    "# Told High Cholestorol -- refused / don't know --> missing \n",
    "df.loc[ (df['BPQ080'] == 7) | (df['BPQ080'] == 9), 'BPQ080'] = np.nan\n",
    "#df.loc[df['BPQ080'].isna(), 'BPQ080'] = 2 \n",
    "df.loc[df['BPQ080'] == 2, 'BPQ080'] = 0 \n",
    "\n",
    "df = df.rename(columns={'BPQ020':'HyperHist','BPQ080':'CholHist'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cardio health \n",
    "\n",
    "Do you ever have chest pain?\n",
    "\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n",
    "  \n",
    "Shortness of breath on stairs or inclines?\n",
    "\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "# Chest pain -- refused / don't know -- > missing  \n",
    "df.loc[ (df['CDQ001'] == 7) | (df['CDQ001'] == 9), 'CDQ001'] = np.nan \n",
    "df.loc[df['CDQ001'] == 2, 'CDQ001'] = 0\n",
    "\n",
    "# Shortness of breath on stairs -- refused / don't know -- > missing  \n",
    "df.loc[ (df['CDQ010'] == 7) | (df['CDQ010'] == 9), 'CDQ010'] = np.nan \n",
    "df.loc[df['CDQ010'] == 2, 'CDQ010'] = 0\n",
    "\n",
    "df = df.rename(columns={'CDQ001':'ChestPain','CDQ010':'Shortness'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diabetes\n",
    "\n",
    "The diabetes column has already been partially cleaned above, here we simply fill in missing values and drop the redundant column.\n",
    "\n",
    "  * 0 -- SP not told they have diabetes\n",
    "  * 1 -- SP told they have borderline diabetes\n",
    "  * 2 -- SP told they have diabetes  \n",
    "  \n",
    "Diabetes age column, for those told they have diabetes. Integer values.\n",
    "\n",
    "  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Diabetes\n",
    " \n",
    "\n",
    "df = df.rename(columns={'DID040':'DiabAge','DIQ010':'DiabHist'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diet Questionaire\n",
    "\n",
    "How often does SP consume Milk.\n",
    "Code as,\n",
    "  * 0 -- Never\n",
    "  * 1 -- Rarely < 1 per week\n",
    "  * 2 -- Sometimes < 1 per day\n",
    "  * 3 -- >= 1 per day\n",
    "  \n",
    "Meals out of the home over the last week, coded as an integer from 0 to 22.\n",
    "\n",
    "Fast food meals over the last week, coded as an integer from 0 to 22.\n",
    "\n",
    "Meals ready to eat over the last 30 days, coded as an integer from 0 to 180."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Diet Behavior & Nutrition\n",
    "\n",
    "# Past 30 days milk consumption.\n",
    "# 'DBQ197' Milk consumption\n",
    "# Default = Sometimes\n",
    "df.loc[(df.DBQ197 > 3), 'DBQ197'] = np.nan\n",
    "#df.loc[(df.DBQ197.isna()), 'DBQ197'] = 2  \n",
    "\n",
    "# How many meals out of the home?\n",
    "# DBD895 > 21 meals -> 22 meals\n",
    "df.loc[(df.DBD895 == 5555), 'DBD895'] = 22\n",
    "# replace refused / don't know --> missing \n",
    "df.loc[(df.DBD895 == 7777) | (df.DBD895 == 9999), 'DBD895'] = np.nan\n",
    "#df.loc[df.DBD895.isna(), 'DBD895'] = df.DBD895.median()\n",
    "\n",
    "# How many fast food meals?\n",
    "# DBD900 \n",
    "df.loc[(df.DBD895 == 0), 'DBD900'] = 0 \n",
    "# DBD900 > 22 meals -> 22 meals\n",
    "df.loc[(df.DBD900 == 5555), 'DBD900'] = 22  \n",
    "# replace refused / don't know  -- > missing\n",
    "df.loc[(df.DBD900 == 7777) | (df.DBD900 == 9999), 'DBD900'] = np.nan\n",
    "#df.loc[df.DBD900.isna(), 'DBD900'] = df.DBD900.median() \n",
    "\n",
    "# How many meals ready to eat?\n",
    "# DBD905\n",
    "# >= 180 set to 180\n",
    "df.loc[(df.DBD905 == 6666), 'DBD905'] = 180  \n",
    "# replace refused / don't know  -- > missing\n",
    "df.loc[(df.DBD905 == 7777) | (df.DBD905 == 9999), 'DBD905'] = np.nan\n",
    "\n",
    "# How many frozen meals?\n",
    "# DBD910\n",
    "# >= 180 set to 180\n",
    "df.loc[(df.DBD910 == 6666), 'DBD910'] = 180  \n",
    "# replace refused / don't know  -- > missing\n",
    "df.loc[(df.DBD910 == 7777) | (df.DBD910 == 9999), 'DBD910'] = np.nan\n",
    "\n",
    "df = df.rename(columns={'DBQ197':'Milk','DBD895':'MealsOut',\n",
    "                        'DBD900':'FastFood','DBD905':'ReadytoEat','DBD910':'Frozen'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kidney Questionaire\n",
    "Questions:\n",
    "\n",
    "Have you ever been told you have weak kidneys?\n",
    "\n",
    "Have you ever had a kidney stones?\n",
    "\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n",
    "  \n",
    "How often do you have urinary leakage?\n",
    "\n",
    "  * 1 -- Never\n",
    "  * 2 -- Less than once a month\n",
    "  * 3 -- A few times a month\n",
    "  * 4 -- A few times a week\n",
    "  * 5 -- Every day and or night\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\n",
    "# Kidney questionaire\n",
    "    \n",
    "# Told Weak kidney (refused / don't know --->  missing\n",
    "df.loc[(df.KIQ022 == 7) | (df.KIQ022 == 9),'KIQ022'] = np.nan\n",
    "#df.loc[df.KIQ022.isna(),'KIQ022'] = 2 \n",
    "df.loc[df['KIQ022'] == 2, 'KIQ022'] = 0 \n",
    "    \n",
    "# Kidney stones (refused / don't know --> missing\n",
    "df.loc[(df.KIQ026 == 7) | (df.KIQ026 == 9),'KIQ026'] = np.nan\n",
    "#df.loc[df.KIQ026.isna(), 'KIQ026'] = 2  \n",
    "df.loc[df['KIQ026'] == 2, 'KIQ026'] = 0 \n",
    "    \n",
    "# Urinary leakage (refused / don't know --> missing \n",
    "df.loc[(df.KIQ005 == 7) | (df.KIQ005 == 9),'KIQ005'] = np.nan\n",
    "#df.loc[df.KIQ005.isna(),'KIQ005'] = 1\n",
    "\n",
    "df = df.rename(columns={'KIQ022':'WeakKidneys','KIQ026':'KidneyStones','KIQ005':'UrineLeak'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dental Health\n",
    "\n",
    "Rate the overall health of your teeth and gums\n",
    "\n",
    "  * 1 -- Excellent\n",
    "  * 2 -- Very good\n",
    "  * 3 -- Good\n",
    "  * 4 -- Fair\n",
    "  * 5 -- Poor\n",
    "  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Dental health (refused / don't know --> missing \n",
    "df.loc[df.OHQ011 > 5,'OHQ011'] = np.nan\n",
    "#df.loc[df.OHQ011.isna(),'OHQ011'] = 3\n",
    "\n",
    "df = df.rename(columns = {'OHQ011':'Dental'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mental health\n",
    "\n",
    "Questions: Over the last 2 weeks how often have you felt\n",
    "1. Feeling down, depressed, or hopeless\n",
    "2. Feeling bad about yourself\n",
    "3. Thought you would be better off dead\n",
    "\n",
    "Each coded as\n",
    "\n",
    "  * 0 -- Not at all\n",
    "  * 1 -- Several days\n",
    "  * 2 -- More than half the days \n",
    "  * 3 -- Nearly every day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "\n",
    "# Felt down  refused / don't know --> missing\n",
    "df.loc[(df.DPQ020 == 7) | (df.DPQ020 == 9),'DPQ020'] = np.nan\n",
    "\n",
    "# Felt bad about yourself refused / don't know --> missing\n",
    "df.loc[(df.DPQ060 == 7) | (df.DPQ060 == 9),'DPQ060'] = np.nan\n",
    "\n",
    "# Suicidality refused / don't know --> missing\n",
    "df.loc[(df.DPQ090 == 7) | (df.DPQ090 == 9),'DPQ090'] = np.nan\n",
    "\n",
    "df = df.rename(columns = {'DPQ020':'FeltDown','DPQ060':'FeltBad','DPQ090':'Suicidality'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Occupation\n",
    "\n",
    "Hours of work over the last week. Integer valued.\n",
    "Starting in year 2015 the values were bounded above by 80 \n",
    "and in 2017 bounded below by 5. We bound all values similarly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Hours worked\n",
    "# Hours worked: refused / don't know --->  missing\n",
    "df.loc[(df.OCQ180 == 77777) | (df.OCQ180 == 99999),'OCQ180'] = np.nan\n",
    "\n",
    "# In some years the hours worked variable, is maxed at 80hours, so we will enforce this over all years.\n",
    "df.loc[(df.OCQ180 >= 80),'OCQ180'] = 80\n",
    "\n",
    "df = df.rename(columns = {'OCQ180':'HoursWorked'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pesticides in the home?\n",
    "\n",
    "In the past 7 days have pesticides been used in the home to control insects?\n",
    "\n",
    "Coded as:\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "\n",
    "# Pesticides  refused / don't know --> missing\n",
    "df.loc[(df.PUQ100 == 7) | (df.PUQ100 == 9),'PUQ100'] = np.nan\n",
    "\n",
    "df.loc[df['PUQ100'] == 2, 'PUQ100'] = 0 \n",
    "\n",
    "df = df.rename(columns = {'PUQ100':'Pesticides'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Physical Activity\n",
    "\n",
    "Does your job involve moderate/vigorous work activity?\n",
    "\n",
    "Do you walk or bike to work?\n",
    "\n",
    "Do you participate in moderate/vigorous recreational activity?\n",
    "\n",
    "Code as,\n",
    " \n",
    "   * 0 -- No\n",
    "   * 1 -- Yes\n",
    "   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Physical Activity questionaire\n",
    "    \n",
    "# Vig work  (refused / don't know --> missing\n",
    "df.loc[(df.PAQ605 == 7) | (df.PAQ605 == 9),'PAQ605'] = np.nan\n",
    "#df.loc[df.PAQ605.isna(),'PAQ605'] = 2   \n",
    "df.loc[df['PAQ605'] == 2, 'PAQ605'] = 0  \n",
    "    \n",
    "# Moderate work  (refused / don't know --> missing\n",
    "df.loc[(df.PAQ620 == 7) | (df.PAQ620 == 9),'PAQ620'] = np.nan\n",
    "#df.loc[df.PAQ620.isna(),'PAQ620'] = 2  \n",
    "df.loc[df['PAQ620'] == 2, 'PAQ620'] = 0  \n",
    "    \n",
    "# Walk / Bike\n",
    "# (refused / don't know --> missing\n",
    "df.loc[(df.PAQ635 == 7) | (df.PAQ635 == 9),'PAQ635'] = np.nan\n",
    "#df.loc[df.PAQ635.isna(),'PAQ635'] = 2     \n",
    "df.loc[df['PAQ635'] == 2, 'PAQ635'] = 0  \n",
    "        \n",
    "# Vig rec (refused / don't know --> missing\n",
    "df.loc[(df.PAQ650 == 7) | (df.PAQ650 == 9),'PAQ650'] = np.nan\n",
    "#df.loc[df.PAQ650.isna(),'PAQ650'] = 2   \n",
    "df.loc[df['PAQ650'] == 2, 'PAQ650'] = 0    \n",
    "    \n",
    "# Moderate rec  (refused / don't know --> missing\n",
    "df.loc[(df.PAQ665 == 7) | (df.PAQ665 == 9),'PAQ665'] = np.nan\n",
    "#df.loc[df.PAQ665.isna(),'PAQ665'] = 2    \n",
    "df.loc[df['PAQ665'] == 2, 'PAQ665'] = 0  \n",
    "     \n",
    "\n",
    "df = df.rename(columns={'PAQ635':'WalkBike','PAQ605':'VigWork',\n",
    "                        'PAQ620':'ModWork','PAQ650':'VigRec','PAQ665':'ModRec'})\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reproductive Health\n",
    "\n",
    "Have you ever been pregnant?\n",
    " \n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n",
    "  \n",
    "Are you pregnant now?\n",
    "\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n",
    "  \n",
    "(Males will be coded as No)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Have you ever been pregnant?\n",
    "\n",
    "# Moderate rec  (refused / don't know --> missing\n",
    "df.loc[(df.RHQ131 == 7) | (df.RHQ131 == 9),'RHQ131'] = np.nan\n",
    "df.loc[df['RHQ131'] == 2, 'RHQ131'] = 0  \n",
    "\n",
    "# Are you pregnant now?\n",
    "# Moderate rec  (refused / don't know --> missing\n",
    "df.loc[(df.RHD143 == 7) | (df.RHD143 == 9),'RHD143'] = np.nan\n",
    "df.loc[df['RHD143'] == 2, 'RHD143'] = 0  \n",
    "\n",
    "# Males coded no\n",
    "df.loc[df['Gender'] == 1, 'RHQ131'] = 0 \n",
    "df.loc[df['Gender'] == 1, 'RHD143'] = 0 \n",
    "\n",
    "df = df.rename(columns={'RHQ131':'PregnantEver','RHD143':'PregnantNow'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sleep\n",
    "\n",
    "How many hours of sleep per night? Continuous valued."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Sleep questionaire\n",
    "\n",
    "# refused / don't know --->  missing\n",
    "df.loc[(df.SLD010H == 77) | (df.SLD010H == 99),'SLD010H'] = np.nan \n",
    "\n",
    "df = df.rename(columns ={'SLD010H':'HoursSlept'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Smoking\n",
    "\n",
    "Have you smoked 100 cigarettes in your life?\n",
    "\n",
    "  * 0 -- No\n",
    "  * 1 -- Yes\n",
    "  \n",
    "Do you now smoke cigarettes?\n",
    "\n",
    "  * 1 -- Every day\n",
    "  * 2 -- Some days\n",
    "  * 3 -- Not at all\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "\n",
    "# Smoking\n",
    "    \n",
    "# Smoking 100 (refused / don't know --> missing\n",
    "df.loc[(df.SMQ020 == 7) | (df.SMQ020 == 9),'SMQ020'] = np.nan\n",
    "#df.loc[df.SMQ020.isna(),'SMQ020'] = 2   \n",
    "df.loc[df['SMQ020'] == 2, 'SMQ020'] = 0  \n",
    "    \n",
    "# Smoking 100 = No >> Currently Smoking = No\n",
    "df.loc[(df.SMQ020 == 2),'SMQ040'] = 3 \n",
    "    \n",
    "# Currently Smoking (refused / don't know --> missing\n",
    "df.loc[(df.SMQ040 == 7) | (df.SMQ040 == 9),'SMQ040'] = np.nan\n",
    "#df.loc[df.SMQ040.isna(),'SMQ040'] = 3   \n",
    "    \n",
    "\n",
    "df = df.rename(columns={'SMQ020':'Smoke100','SMQ040':'SmokeNow'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight History\n",
    "\n",
    "Self reported maximum weight, range of integer values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\n",
    "# self reported max weight refused / don't know --> missing\n",
    "df.loc[(df.WHD140 == 7777) | (df.WHD140 == 9999),'WHD140'] = np.nan\n",
    "\n",
    "#This self reported value is in pounds, however, later we will import a weight in kg. We will transform this column to kg.\n",
    "df.loc[:,'WHD140'] = df['WHD140'].div(2.2046)\n",
    "\n",
    "df = df.rename(columns={'WHD140':'MaxWeight'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fasting / Session Time\n",
    "The fasting time originates from the Blood Glucose Laboratory Survey. It is not clear if this will correlate with the blood pressure outcomes, but it will be imported in the case that it is.\n",
    "\n",
    "The fast time is reported as a non negative integer.\n",
    "\n",
    "The session time is coded as\n",
    "  * 1 -- Morning\n",
    "  * 2 -- Afternoon\n",
    "  * 3 -- Evening"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Food fast hours / Session time\n",
    "\n",
    "df = df.rename(columns={'PHAFSTHR':'FoodFastHours','PHDSESN':'SessionTime'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Body Measurements\n",
    "\n",
    "Measurements include:\n",
    " * BMI\n",
    " * Waist\n",
    " * Leg Length\n",
    " * Arm Length\n",
    " * Arm Circumference\n",
    " \n",
    "Missing values will be replaced by the median"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Body measurement\n",
    "\n",
    "# BMXBMI BMI measurement\n",
    "# replace missing with median\n",
    "#df.loc[(df.BMXBMI.isna()),'BMXBMI'] = df.BMXBMI.median()\n",
    "#df.loc[(df.BMXWAIST.isna()),'BMXWAIST'] = df.BMXWAIST.median()\n",
    "#df.loc[(df.BMXLEG.isna()),'BMXLEG'] = df.BMXLEG.median()\n",
    "#df.loc[(df.BMXARML.isna()),'BMXARML'] = df.BMXARML.median()\n",
    "#df.loc[(df.BMXARMC.isna()),'BMXARMC'] = df.BMXARMC.median()\n",
    "\n",
    "df = df.rename(\n",
    "    columns={'BMXBMI':'BMI','BMXWAIST':'Waist','BMXLEG':'LegLen','BMXARML':'ArmLen','BMXARMC':'ArmCirc','BMXWT':'Weight'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Circulatory Measurements\n",
    "\n",
    "Measurements include:\n",
    " * Food in the last 30 min\n",
    " * Pulse\n",
    " * Systolic pressure\n",
    " * Diastolic pressure\n",
    "\n",
    "Missing pulse values will be replaced with the median. \n",
    "\n",
    "There are 3 measurements for each of Systolic and Diastolic pressure, we take the average and then drop the outliers that are likely due to measurement error.\n",
    "\n",
    "Those rows with missing Systolic and Diastolic averages will be dropped.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "\n",
    "\n",
    "# Pulse\n",
    "#df.loc[(df.BPXPLS.isna()),'BPXPLS'] = df.BPXPLS.median()\n",
    "\n",
    "# Create Systolic / Diastolic pressure as the average of the measurements\n",
    "\n",
    "df['Systolic'] = df.loc[:,['BPXSY1','BPXSY2','BPXSY3']].mean(axis = 1)\n",
    "df['Diastolic'] = df.loc[:,['BPXDI1','BPXDI2','BPXDI3']].mean(axis = 1)\n",
    "\n",
    " \n",
    "df = df.drop(['BPXSY1','BPXSY2','BPXSY3','BPXDI1','BPXDI2','BPXDI3'],axis = 1)\n",
    "df = df.dropna(how = 'any', subset = ['Systolic','Diastolic'])\n",
    "\n",
    "\n",
    "\n",
    "df = df.rename(columns={'BPXPLS':'Pulse'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\n",
    "\n",
    "df = df.rename(columns={'LBDHDD':'HDL','LBDLDL':'LDL','LBXTR':'Tryglicerides','LBXTC':'TChol'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Let's check missing values\n",
    "print('Missing values per feature:')\n",
    "df.isna().sum(axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing values per feature:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Ethnicity            0\n",
       "Age                  0\n",
       "Education            0\n",
       "Gender               0\n",
       "HHIncome          2108\n",
       "Alcohol           6698\n",
       "HyperHist           41\n",
       "CholHist          3467\n",
       "ChestPain        10561\n",
       "Shortness        10588\n",
       "DiabAge          27728\n",
       "DiabHist            22\n",
       "Frozen              45\n",
       "FastFood            30\n",
       "ReadytoEat          76\n",
       "MealsOut            24\n",
       "Milk               121\n",
       "KidneyStones        80\n",
       "WeakKidneys         46\n",
       "UrineLeak         2597\n",
       "Suicidality       2708\n",
       "FeltDown          2689\n",
       "FeltBad           2712\n",
       "HoursWorked         38\n",
       "Dental            1327\n",
       "Pesticides        2371\n",
       "ModRec               5\n",
       "WalkBike             1\n",
       "VigRec               2\n",
       "ModWork             14\n",
       "VigWork              8\n",
       "PregnantEver      1550\n",
       "PregnantNow      12293\n",
       "HoursSlept         103\n",
       "Smoke100            21\n",
       "SmokeNow             3\n",
       "MaxWeight          522\n",
       "Pulse                2\n",
       "Weight             303\n",
       "ArmCirc           1172\n",
       "BMI                359\n",
       "LegLen            1561\n",
       "ArmLen            1168\n",
       "Waist             1503\n",
       "HDL               1803\n",
       "Tryglicerides    17663\n",
       "LDL              17897\n",
       "TChol             1803\n",
       "FoodFastHours      486\n",
       "SessionTime          0\n",
       "LBXGLU           17243\n",
       "Systolic             0\n",
       "Diastolic            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These values will have to be imputed in the EDA notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df.to_pickle(\"clean_data.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}